{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lyon2 geonum](https://perso.liris.cnrs.fr/lmoncla/GEONUM/fig/logos.png)\n",
    "\n",
    "# 2A3 – Modélisation et structuration de données géographiques et applications SGBD spatiaux\n",
    "\n",
    "## Tutoriel : Analyse des données des disponibilités des stations Vélo'v de la Métropole de Lyon\n",
    "\n",
    "# Partie 3 : Un peu de science des données\n",
    "\n",
    "\n",
    "L'objectif de cette partie du tutoriel est de continuer l'analyse des données velo'v et d'expérimenter des méthodes d'intelligence artificielle pour faire de la prédiction des disponibilités vélo'v en ajoutant les données des conditions météo.\n",
    "\n",
    "Les objectifs de cette partie sont les suivants : \n",
    "\n",
    "* Récupérer le jeu de données météo et l'associer à celui des velo'v.\n",
    "* Visualiser les données selon cette nouvelle couche météo.\n",
    "* Entraîner un modèle de prédiction de la demande des vélo'v.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configurer l'environnement\n",
    "\n",
    "### 1.2 Télécharger les fichiers et installer les librairies (seulement pour Google Colab)\n",
    "\n",
    "* Si vous avez déjà configuré votre environnement, soit avec conda, soit avec pip (voir le fichier [README.md](https://gitlab.liris.cnrs.fr/lmoncla/tutoriel-anf-tdm-2022-python-geoparsing/-/blob/main/README.md)), vous pouvez ignorer la section suivante et passer directement à la section 1.2.\n",
    "* Si vous exécutez ce notebook depuis Google Colab, vous devez exécuter les cellules suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/ludovicmoncla/master-geonum-tutorials.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r master-geonum-tutorials/requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import folium\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import geopandas\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Récupération des jeux de données\n",
    "\n",
    "Comme pour la Partie 1, l'ensemble des données utilisées dans ce tutoriel est disponible à cette adresse : \n",
    "https://perso.liris.cnrs.fr/lmoncla/GEONUM/\n",
    "\n",
    "* Télécharger les fichiers contenant les données\n",
    "1. data-stations.zip\n",
    "2. data-bikes-2.zip\n",
    "3. data-weather-lyon.csv\n",
    "\n",
    "Les 2 zip contiennent chacun un fichier CSV contenant respectivement la liste des stations vélov (et leur localisation) et la liste des disponibilités de chaque station par tranche de 30 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On commence par créer un dossier dans lequel on va télécharger les données\n",
    "## Peut être fait directement depuis l'explorateur de fichiers\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on se déplace dans le nouveau dossier\n",
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On télécharge l'archive contenant la liste des stations\n",
    "!wget https://perso.liris.cnrs.fr/lmoncla/GEONUM/data-stations.zip\n",
    "    \n",
    "## On télécharge l'archive contenant la liste des disponibilité des stations par tranche de 5 minutes\n",
    "!wget https://perso.liris.cnrs.fr/lmoncla/GEONUM/data-bikes-2.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Chargement des données\n",
    "\n",
    "Nous chargeons les mêmes jeux de données que dans le tutoriel précédent :\n",
    "\n",
    "1. les stations vélo'v (id station, latitude, longitude),\n",
    "2. leurs historiques (id station, année, mois, jour, heure, minute, date, vélos disponibles, places disponibles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## On charge les données des stations dans un dataframe\n",
    "df_stations = *****\n",
    "\n",
    "## On crée maintenant le dataframe avec les données d'historique\n",
    "df_bikes = *****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche les premières lignes\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de la taille en mémoire\n",
    "\n",
    "## on transforme le type des colonnes en entier ou float lorsque cela est nécessaire\n",
    "df_bikes['time'] = pd.to_datetime(df_bikes['time']) \n",
    "df_bikes[['year', 'daily_departure', 'daily_arrival']] = df_bikes[['year', 'daily_departure', 'daily_arrival']].astype('int16')\n",
    "df_bikes[['month','day','hour','minute', 'bikes', 'bike_stands', 'departure30min','arrival30min', 'day_of_week']] = df_bikes[['month','day','hour','minute', 'bikes', 'bike_stands', 'departure30min','arrival30min', 'day_of_week']].astype('int8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ajout d'une couche de données supplémentaire : la météo\n",
    "\n",
    "\n",
    "### 3.1 Chargement des données\n",
    "\n",
    "\n",
    "Le fichier `data-weather-lyon.csv` contient les données météo par heure pour l'année 2021 pour Lyon.\n",
    "\n",
    "Le jeu de données météo correspond au dataset `NASA/POWER CERES/MERRA2 Native Resolution Hourly Data` récupéré grâce à l'API du site POWER Project de la NASA : https://power.larc.nasa.gov/.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On télécharge l'archive contenant les données météo\n",
    "!wget https://perso.liris.cnrs.fr/lmoncla/GEONUM/data-weather-lyon.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On charge les données météo dans un dataframe\n",
    "df_weather = pd.read_csv('data-weather-lyon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche les premières lignes\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Premier apercu des données météo\n",
    "\n",
    "Les colonnes du jeu de données météo sont les suivantes : \n",
    "\n",
    "- WD10M           MERRA-2 Wind Direction at 10 Meters (Degrees) \n",
    "- T2M             MERRA-2 Temperature at 2 Meters (C) \n",
    "- RH2M            MERRA-2 Relative Humidity at 2 Meters (%) \n",
    "- QV2M            MERRA-2 Specific Humidity at 2 Meters (g/kg) \n",
    "- T2MDEW          MERRA-2 Dew/Frost Point at 2 Meters (C) \n",
    "- U10M            MERRA-2 Eastward Wind at 10 Meters (m/s) \n",
    "- PS              MERRA-2 Surface Pressure (kPa) \n",
    "- T2MWET          MERRA-2 Wet Bulb Temperature at 2 Meters (C) \n",
    "- WS10M           MERRA-2 Wind Speed at 10 Meters (m/s) \n",
    "- V10M            MERRA-2 Northward Wind at 10 Meters (m/s) \n",
    "- PRECTOTCORR     MERRA-2 Precipitation Corrected (mm/hour) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser la méthode [drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) pour supprimer les colonnes que l'on ne souhaite pas conserver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On supprime les colonnes inutiles\n",
    "## On ne souhaite conserver que les colonnes température, vitesse du vent et pluviométrie.\n",
    "\n",
    "df_weather = *****\n",
    "\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Utiliser la méthode [rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html) pour renommer les colonnes restantes afin de pouvoir faire une jointure avec les données de disponibilité vélo'v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On renomme les colonnes pour ensuite faire une jointure de ce dataframe avec celui des données vélo'v\n",
    "\n",
    "df_weather = *****\n",
    "\n",
    "df_weather.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche les moyennes des températures, précipitation et vent par mois sur 3 graphiques différents\n",
    "\n",
    "fig,(ax1,ax2,ax3)= plt.subplots(nrows=3)\n",
    "fig.set_size_inches(12,20)\n",
    "\n",
    "monthAggregated = pd.DataFrame(*****).reset_index()\n",
    "monthSorted = monthAggregated.sort_values(by='temperature', ascending = False) \n",
    "sn.barplot(data=monthSorted, x = 'month', y = 'temperature', ax=ax1)\n",
    "ax1.set(xlabel='Month', ylabel='Average Temperature', title='Average Temperature by Month') \n",
    "\n",
    "monthAggregated = pd.DataFrame(*****).reset_index()\n",
    "monthSorted = monthAggregated.sort_values(by='precipitation', ascending = False) \n",
    "sn.barplot(data=monthSorted, x = 'month', y = 'precipitation', ax=ax2)\n",
    "ax2.set(xlabel='Month', ylabel='Average Precipitation', title='Average Precipitation by Month') \n",
    "\n",
    "monthAggregated = pd.DataFrame(*****).reset_index()\n",
    "monthSorted = monthAggregated.sort_values(by='vent', ascending = False) \n",
    "sn.barplot(data=monthSorted, x = 'month', y = 'vent', ax=ax3)\n",
    "ax3.set(xlabel='Month', ylabel='Average Wind Speed', title='Average Wind Speed by Month') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser la méthode [merge()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) pour combiner les données de disponibilité des velo'v avec les données méteo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On ajoute les données météo dans le dataframe qui contient les données de disponibilité\n",
    "df_bikes = *****\n",
    "df_bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entraînement d'un modèle de prédiction\n",
    "\n",
    "### 4.1 Import de la librairie (scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Préparation des données pour l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On fait une copie de notre DataFrame, pour pouvoir revenir aux données initiales si besoin\n",
    "df_data = df_bikes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sépare le jeu de données en entrées et sorties pour l'apprentissage\n",
    "\n",
    "# les inputs correspondent aux données fournis au modèle pour pouvoir apprendre. \n",
    "inputs = *****\n",
    "\n",
    "# les labels correspondent aux valeurs que l'on souhaite prédire et donc que le modèle doit apprendre\n",
    "labels = *****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des méthodes d'apprentissage ne peuvent utiliser que des variables numériques. Il faut donc transformer les variables catégorielles telle que `id_velov` ou `day_of_week` afin qu'elles puissent servir lors de l'apprentissage. \n",
    "\n",
    "Pour cela on utilise la fonction [LabelEncoder()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) de la librairie scikit-learn. Elle permet de transformer des valeurs de type chaine de caractère en numérique par association. Par exemple : lundi -> 0, mardi -> 1, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On transforme les variables catégorielles en variables numériques\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# on entraîne l'encoder pour qu'il ai vu toutes les valeurs possibles\n",
    "encoder.fit(df_stations.id_velov)\n",
    "\n",
    "# on transforme la colonne id_velov\n",
    "inputs['id_velov'] = encoder.transform(inputs['id_velov'])\n",
    "\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que les données sont prêtes et que les variables sont au bon format. Il faut maintenant séparer le jeu de données pour utiliser une partie des données pour l'entraînement et une autre partie pour l'évaluation. \n",
    "\n",
    "Pour cela on utilise la méthode [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) qui permet de séparer le jeu de données en 2 de manière aléatoire pour que les jeux d'entrainement et d'évaluation aient les mêmes caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sépare le jeu de données en 2 : un jeu d'entraînement et un jeu de test\n",
    "x_train, x_test, y_train, y_test = *****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Entraînement supervisé des modèles\n",
    "\n",
    "L'ensemble des algoritmes d'apprentissage supervisée implémentés dans la librairie Scikit-Learn sont disponibles ici : https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "Dans notre cas, nous souhaitons prédire des valeurs continues par opposition aux valeurs discrètes. Nous allons donc utiliser des modèles de régression et non pas des modèles de classification.\n",
    "\n",
    "Je vous propose de tester et comparer 2 méthodes : [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) et [RandomForestRegressor](https://scikit-learn.org/0.15/modules/generated/sklearn.ensemble.RandomForestRegressor.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On déclare un modèle de type RadomForestRegressor et on l'entraîne sur le jeu d'entraînement\n",
    "clf_lr = *****\n",
    "\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise le modèle pour faire la prédiction sur le jeu de test\n",
    "predictions_lr = *****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On déclare un modèle de type RadomForestRegressor et on l'entraîne sur le jeu d'entraînement\n",
    "clf_rf = *****\n",
    "*****\n",
    "\n",
    "# !! Cette cellule peut mettre plusieurs minutes à s'executer (entre 5 et 10 min) !! #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Enregistrer le modèle dans un fichier pour pouvoir le réutiliser plus tard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(clf_rf, './model-velov-demand-prediction.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Charger le modèle depuis le fichier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "clf_rf = load('./model-velov-demand-prediction.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise le modèle pour faire la prédiction sur le jeu de test\n",
    "predictions_rf = *****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Evaluation et comparaison\n",
    "\n",
    "Afin d'évaluer nos modèles de prédiction, on utilise la mesure [MAE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) (Mean Absolute Error) : \n",
    "$$\\frac{\\sum_{i=1}^n \\left\\lvert \\hat{y}_i - y_i \\right\\rvert}{n}$$ \n",
    "qui permet de mesurer l'écart moyen absolu entre les prédictions et les valeurs à prédire. Plus cette valeur est faible, meilleur est notre modèle.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule l'erreur moyenne en comparant les prédictions avec les valeurs qu'il fallait prédire\n",
    "\n",
    "mae_lr = *****\n",
    "\n",
    "print('linear regression mae : ', mae_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule l'erreur moyenne en comparant les prédictions avec les valeurs qu'il fallait prédire\n",
    "\n",
    "mae_rf = *****\n",
    "\n",
    "print('random forest regression mae : ', mae_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que l'erreur moyenne est nettement plus faible pour le modèle random forest ! En moyenne l'écart entre la prédiction et la réalité est de 1. Ce qui parait plutôt satisfaisant pour notre tâche. Dans le cas de l'utilisation de ce modèle dans une application, il faudrait prévenir l'utilisateur que la prédiction est en moyenne correcte à plus ou moins 1 vélo !\n",
    "\n",
    "On souhaite maintenant afficher une évaluation sous forme de graphique. Le jeu de test contenant plus d'un million de lignes, on isole au préalable un échantillon de 100 données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regroupe les valeurs à prédire et les prédictions au sein d'un même tableau\n",
    "t = np.stack((y_test, predictions_rf, predictions_lr), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On vérifie la taille du tableau\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche un aperçu des valeurs\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sélectionne un échantillon de 100 prédictions pour afficher la comparaison\n",
    "\n",
    "idx = np.random.randint(t.shape[1], size=100)\n",
    "sample = t[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Comparaison des prédictions\")\n",
    "plt.xlabel(\"Echantillon\")\n",
    "plt.ylabel(\"Vélos disponibles\")\n",
    "plt.plot(range(100), sample[0], color =\"green\", label=\"Vérité\")\n",
    "plt.plot(range(100), sample[1], color =\"blue\", label=\"Random Forest\")\n",
    "plt.plot(range(100), sample[2], color =\"red\", label=\"Linear Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaite maintenant afficher le même type de graphique mais au lieu d'afficher la prédiction on veut afficher l'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rf = abs(sample[0]-sample[1])\n",
    "err_lr = abs(sample[0]-sample[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Comparaison des prédictions\")\n",
    "plt.xlabel(\"Echantillon\")\n",
    "plt.ylabel(\"Erreur\")\n",
    "plt.plot(range(100), err_rf, color =\"blue\", label=\"Random Forest\")\n",
    "plt.plot(range(100), err_lr, color =\"red\", label=\"Linear Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Utilisation du modèle\n",
    "\n",
    "La météo a-t-elle un impact sur la prédiction ?\n",
    "\n",
    "Pour le savoir, nous pouvons faire une prédiction de la disponibilité à une station pour une certaine date en faisant varier la météo et observer s'il y a des différences entre les prédictions.\n",
    "\n",
    "Le modèle prend en entrée 10 paramètres :\n",
    "- id_velov\n",
    "- year\n",
    "- month\n",
    "- day\n",
    "- hour\n",
    "- minute\n",
    "- day_of_week\n",
    "- temperature\n",
    "- vent\n",
    "- precipitation\n",
    "\n",
    "On se propose de faire une prédiction pour samedi prochain à 8h à la station 3094 (Gare Part-Dieu). \n",
    "On fait la prédiction pour 2 cas différents : beau et mauvais temps\n",
    "1. Beau temps : température = 20, vent = 1, précipitations = 0\n",
    "2. Mauvais temps : température = 8, vent = 3, précipitations = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encoder le nom de la station\n",
    "st = encoder.transform(['velov-3094'])\n",
    "\n",
    "\n",
    "d_nice = [[st, 2021, 2, 10, 8, 0, 5, 20, 1, 0]]\n",
    "d_bad = [[st, 2021, 2, 10, 8, 0, 5, 8, 3, 0.10]]\n",
    "\n",
    "# on calcule les prédictions\n",
    "p_nice = *****\n",
    "p_bad = *****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_nice)\n",
    "print(p_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque donc que la météo a bien un impact sur la prédiction. Il y aura plus de vélos disponibles en cas de mauvais temps que de beau temps !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercices\n",
    "\n",
    "En reprenant le code des séances précédentes proposer une carte de la disponibilité des vélo'v pour l'ensemble des stations basée sur les prédictions de samedi prochain à 8h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer une carte permettant de visualiser la différence entre beau et mauvais temps pour la même date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geonum-velov-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c867f1bf842768b9b0df3131f4ae7fc0b5c315d176d92e8f9ae8f628e957bf43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lyon2 geonum](https://perso.liris.cnrs.fr/lmoncla/GEONUM/fig/logos.png)\n",
    "\n",
    "# 2A3 – Modélisation et structuration de données géographiques et applications SGBD spatiaux\n",
    "\n",
    "\n",
    "## Tutoriel : Analyse des données des disponibilités des stations Vélo'v de la Métropole de Lyon\n",
    "\n",
    "\n",
    "# Partie 1 : Exploration de données\n",
    "\n",
    "\n",
    "L'objectif de ce tutoriel est d'appréhender la problématique d'analyse de données spatio-temporelles grâce à l'utilisation de librairies Python.\n",
    "Pour cela nous allons travailler sur un cas d'étude visant la visualisation et le traitement des données de disponibilités des stations Vélo'v de la Métropole de Lyon. \n",
    "\n",
    "Les données que nous allons utilisées proviennent de la [plateforme data du Grand Lyon](https://data.grandlyon.com). Elles sont mises à disposition gratuitement par la métropole de Lyon et peuvent être téléchargées dans différents formats : https://data.grandlyon.com/jeux-de-donnees/historique-disponibilites-stations-velo-v-metropole-lyon/donnees\n",
    "Depuis le site du Grand Lyon, seuls les 7 derniers jours sont disponibles.\n",
    "\n",
    "\n",
    "![site du grand lyon](https://perso.liris.cnrs.fr/lmoncla/GEONUM/fig/grandlyon.png)\n",
    "\n",
    "\n",
    "Dans le cadre de ce TP,  vous avez à votre disposition l'ensemble des données pour la période du 7 octobre 2020 au 31 janvier 2021.\n",
    "\n",
    "\n",
    "Les objectifs de ce tutoriel sont les suivants : \n",
    "\n",
    "* Récupérer le jeu de données, analyser sa structure et le charger dans un dataframe\n",
    "* Explorer et visualiser les données\n",
    "* Analyser les données : requêter le jeu de données pour générer des graphiques, des cartes et des cartes animées.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configurer l'environnement\n",
    "\n",
    "### 1.2 Télécharger les fichiers et installer les librairies (seulement pour Google Colab)\n",
    "\n",
    "* Si vous avez déjà configuré votre environnement, soit avec conda, soit avec pip (voir le fichier [README.md](https://gitlab.liris.cnrs.fr/lmoncla/tutoriel-anf-tdm-2022-python-geoparsing/-/blob/main/README.md)), vous pouvez ignorer la section suivante et passer directement à la section 1.2.\n",
    "* Si vous exécutez ce notebook depuis Google Colab, vous devez exécuter les cellules suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/ludovicmoncla/master-geonum-tutorials.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r master-geonum-tutorials/requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import folium\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Récupération du jeu de données\n",
    "\n",
    "Pour palier la limite des 7 jours de disponibilité sur le site du Grand Lyon, j'ai développé un script qui récupère et stocke automatiquement les données chaque jour. Vous aurez ainsi accès aux données pour l'ensemble de l'année 2021. \n",
    "Je propose également les données au format CSV (plus simple à charger dans un dataframe qui le format JSON d'origine). Nous verrons la transformation du format de données lors de la dernière séance.\n",
    "\n",
    "L'ensemble des données utilisées dans ce tutoriel est disponible à cette adresse : \n",
    "https://perso.liris.cnrs.fr/lmoncla/GEONUM/\n",
    "\n",
    "* Télécharger les archives contenant les données\n",
    "1. data-stations.zip\n",
    "2. data-bikes.zip\n",
    "\n",
    "Ces 2 archives contiennent chacune un fichier CSV contenant respectivement la liste des stations vélov (et leur localisation) et la liste des disponibilités de chaque station par tranche de 30 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On commence par créer un dossier dans lequel on va télécharger les données\n",
    "## Peut être fait directement depuis l'explorateur de fichiers\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on se déplace dans le nouveau dossier\n",
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On télécharge l'archive contenant la liste des stations\n",
    "!wget https://perso.liris.cnrs.fr/lmoncla/GEONUM/data-stations.zip\n",
    "    \n",
    "## On télécharge l'archive contenant la liste des disponibilité des stations par tranche de 5 minutes\n",
    "!wget https://perso.liris.cnrs.fr/lmoncla/GEONUM/data-bikes.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Chargement des données\n",
    "\n",
    "Dans ce tutoriel nous n'allons pas utiliser de SGBD. L'objectif est de charger l'ensemble des données en mémoire dans une structure Python et de l'interroger directement. \n",
    "\n",
    "On distingue deux types de données :\n",
    "1. les stations vélo'v (id station, latitude, longitude),\n",
    "2. leurs historiques (id station, année, mois, jour, heure, minute, date, vélos disponibles, places disponibles).\n",
    "\n",
    "Pour manipuler ces données nous allons utiliser les [dataframes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) de la librairie Pandas.\n",
    "\n",
    "Pandas est une librairie Python spécialisée dans l'analyse et la manipulation de données. Elle fourni en particulier un objet de type 'dataframe' qui permet de réaliser des opérations de prétraitement et de filtrage que nous utiliserons pour requêter les données.\n",
    "\n",
    "Les premiers objectifs sont les suivants :\n",
    "\n",
    "1. Stocker dans un premier dataframe la liste des stations velo'v et leurs coordonnées latitude / longitude associées.\n",
    "2. Stocker dans un second dataframe pour chaque station et chaque pas de temps les données suivantes : \n",
    "    * id de la station\n",
    "    * année\n",
    "    * mois\n",
    "    * jour\n",
    "    * heure\n",
    "    * minute\n",
    "    * date complète (format d'origine)\n",
    "    * nombre de vélos disponibles\n",
    "    * nombre de places libres\n",
    "    * nombre de départs des 30 dernières minutes\n",
    "    * nombre d'arrivées des 30 dernières minutes\n",
    "\n",
    "\n",
    "Pour charger les données il suffit d'utiliser la méthode [read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv) de la librairie `Pandas`. Elle prend en paramètre le chemin du fichier que l'on souhaite charger. Ce fichier peut être de 2 formats, soit directement un fichier CSV, soit un fichier ZIP contenant un CSV. Dans notre, cas il est donc inutile de dézipper les archives téléchargées précédemment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## On charge les données des stations dans un dataframe\n",
    "df_stations = pd.read_csv('data-stations.zip')\n",
    "\n",
    "## On crée maintenant le dataframe avec les données d'historique\n",
    "df_bikes = pd.read_csv('data-bikes.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On vérifie le type de notre variable\n",
    "type(df_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche la liste des colonnes\n",
    "df_stations.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche les premières lignes\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combien y a-t-il de stations velo'v ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche la taille du dataframe\n",
    "## La méthode shape retourne les dimensions (lignes / colonnes)\n",
    "print(df_stations.shape)\n",
    "\n",
    "## La fonction len() retourne le nombre de ligne\n",
    "print(len(df_stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche les premières lignes\n",
    "df_bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Premier apercu des données d'historique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche les information sur les données\n",
    "df_bikes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de la taille en mémoire\n",
    "\n",
    "## on transforme le type des colonnes en entier ou float lorsque cela est nécessaire\n",
    "df_bikes.bikes = df_bikes.bikes.apply(lambda x: int(float(x)))\n",
    "df_bikes.bike_stands = df_bikes.bike_stands.apply(lambda x: np.int32(float(x)))\n",
    "\n",
    "df_bikes['year'] = df_bikes['year'].astype('int16')\n",
    "df_bikes[['month','day','hour','minute', 'bikes', 'bike_stands', 'departure30min','arrival30min']] = df_bikes[['month','day','hour','minute', 'bikes', 'bike_stands', 'departure30min','arrival30min']].astype('int8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche les information sur les données\n",
    "df_bikes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Description des données\n",
    "df_bikes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche 5 lignes sélectionnées de manière aléatoire\n",
    "df_bikes.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Manipulation d'un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accès à une colonne\n",
    "df_bikes['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accès à une colonne (autre manière en utilisant le .)\n",
    "df_bikes.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accès à un ensemble de colonnes\n",
    "df_bikes[['time', 'bikes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Récupérer les valeurs d'un ensemble de colonnes\n",
    "df_bikes[['time', 'bikes']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une colonne (ou variable) est un vecteur de données (Series dans la terminologie de la librarie Pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Affichage des premières valeurs d'une seule colonne\n",
    "df_bikes['time'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Affichage des dernières valeurs de la colonne\n",
    "df_bikes['time'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On trie les valeurs d'une colonne de manière croissante\n",
    "df_bikes['time'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Le tri peut également être généralisé aux DataFrame\n",
    "## Tri du jeu de données selon l'id de la station et la date\n",
    "df_bikes.sort_values(by=['id_velov', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative permettant de remettre l'index des lignes à zéro\n",
    "df_bikes = df_bikes.sort_values(by=['id_velov', 'time']).reset_index(drop=True)\n",
    "df_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comptage des valeurs\n",
    "df_bikes['id_velov'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## une colonne étant un vecteur il est possible d'utiliser des indices pour accèder aux éléments\n",
    "## Affichage de la première valeur de la colonne time\n",
    "df_bikes['time'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Affichage des 3 premières valeurs de la colonne time\n",
    "df_bikes['time'][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Itérations sur les colonnes (variables)\n",
    "\n",
    "Les itérations sur les variables peuvent se faire via une boucle, ou via l'utilisation de fonctions callback appelée à l'aide d'une fonction `.apply()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boucler sur l'ensemble des colonne pour afficher leur nom et leur type\n",
    "for col in df_bikes.columns:\n",
    "    print(col, \": \", df_bikes[col].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Itérations sur les lignes (\\*\\*déconseillé dans le cas des grands dataframe**)\n",
    "\n",
    "\n",
    "Il est possible de parcourir les lignes d'un dataframe, mais attention, l'itération sur un dataframe est lent. Mieux vaut utiliser des opérations vectorielles ! Si on ne peut pas, on préfére utiliser une fonction callback appelée à l'aide d'une fonction `.apply()`.\n",
    "\n",
    "Remarque : on ne peut pas modifier un dataframe sur lequel on boucle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pour l'exemple, on itère sur le dataframe des stations (car celui de l'historique est trop grand)\n",
    "for index, row in df_stations.iterrows():\n",
    "    print('ID :', row.id_velov, '\\t lat :', row.latitude,'\\t lng :', row.longitude)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Accès indicé aux données d'un DataFrame\n",
    "\n",
    "On peut accéder aux valeurs du DataFrame via des indices ou plages d'indices. \n",
    "La structure se comporte alors comme une matrice. La cellule en haut à gauche est de coordonnées (0,0).\n",
    "Il y a différentes manières de le faire, l'utilisation de `.iloc[,]` constitue une des solutions les plus simples.\n",
    "Rappel : la méthode `shape()` permet d'obtenir les dimensions (lignes et colonnes) du DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accès à la valeur située en (0,0) (première ligne, première colonne)\n",
    "df_bikes.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Valeur située en dernière ligne, première colonne\n",
    "## Utilisation de l'indiçage négatif\n",
    "df_bikes.iloc[-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative avec shape, valeur située en dernière ligne, première colonne\n",
    "## shape[0] renvoie le nombre de lignes (première dimension)\n",
    "## il faut réduire de -1 parce le premier indice est égal à 0 sinon on déborde\n",
    "df_bikes.iloc[df_bikes.shape[0]-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Affichage des 5 premières valeurs de toutes les colonnes\n",
    "## lignes => 0:5 (0 à 5 [non inclus])\n",
    "## colonnes = : (toutes les colonnes)\n",
    "df_bikes.iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Avec l'indiçage négatif, on peut facilement accéder aux 5 dernières lignes\n",
    "df_bikes.iloc[-5:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 premières lignes et colonnes 0, 6, 7 et 8\n",
    "## on a une liste d'indices en colonne\n",
    "df_bikes.iloc[0:5,[0,6,7,8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Filtrage avec des conditions - Les requêtes\n",
    "\n",
    "Nous pouvons isoler les sous-ensembles d'observations répondant à des critères définis sur les champs. Nous utiliserons préférentiellement la méthode `.loc[,]` dans ce cadre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Liste des données d'historique pour la station 'velov-10001'\n",
    "df_bikes.loc[df_bikes['id_velov']==\"velov-10001\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pour un ensemble de valeurs de la même variable, on utilise la méthode isin()\n",
    "df_bikes.loc[df_bikes['id_velov'].isin(['velov-10001','velov-10002']),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des opérateurs logiques permettent de combiner les conditions. \n",
    "On utilise respectivement : & pour ET, | pour OU, et ~ pour la négation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Liste des données pour la station 'velov-10001' et hour = 8\n",
    "df_bikes.loc[(df_bikes['id_velov']==\"velov-10001\") & (df_bikes['hour'] == 8),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Liste des données datant d'après juillet\n",
    "df_bikes.loc[(df_bikes['month'] > 7),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on peut n'afficher qu'une partie des colonnes\n",
    "#on définit la projection dans une liste\n",
    "colonnes = ['id_velov','time','bikes','bike_stands']\n",
    "#que l'on utilise en paramètre dans .loc[]\n",
    "#pour la même restruction que précédemment\n",
    "df_bikes.loc[(df_bikes['month'] > 7),colonnes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Regroupement des variables\n",
    "\n",
    "L'utilisation de `groupby()` permet d'accéder aux sous-DataFrame associés à chaque item de la variable de regroupement. Il est dès lors possible d'appliquer explicitement d'autres traitements sur ces sous-ensembles de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regroupement des données selon le l'id de la station\n",
    "g = df_bikes.groupby('id_velov')\n",
    "\n",
    "g.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculer la dimension du sous-DataFrame associé à la station 'velov_10001'\n",
    "g.get_group('velov-10001').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Visualisation des localisations des stations\n",
    "\n",
    "Maintenant que vous avez chargé les données en mémoire et vue comment manipuler un `DataFrame`, vous allez produire votre première carte.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Utilisation des librairies GeoPandas et Plotly \n",
    "\n",
    "La librairie [GeoPandas](https://geopandas.org/) est conçu pour faciliter la manipulation de données spatiales. La particularité de GeoPandas est qu'elle permet de manipuler les données spatiales comme s'il s'agissait de données traditionnelles. \n",
    "\n",
    "Par rapport à un `DataFrame` standard, un `GeoDataFrame`, comporte une colonne supplémentaire: `geometry`. Comme dans un SGBD spatial, cette colonne permet de stocker les contours (la géométrie) d'un objet géographique. Un objet `GeoDataFrame` hérite des propriétés d'un `DataFrame` mais propose des méthodes adaptées au traitement des données spatiales.\n",
    "\n",
    "Ainsi en plus des manipulations déjà possible avec pandas, on pourra manipulation la dimension spatiale : \n",
    "- calculer des distances et des surfaces,\n",
    "- agréger rapidement des zonages (regrouper les départements en région par exemple),\n",
    "- rechercher une zone à partir des coordonnées d'un point,\n",
    "- convertir les données dans différents systèmes de projection,\n",
    "- faire une carte.\n",
    "\n",
    "Pour le moment on s'intèresse au dernier point afin de produire une carte des stations Velo'v.\n",
    "\n",
    "![stations velov avec GeoPandas](https://perso.liris.cnrs.fr/lmoncla/GEONUM/fig/geopandas_stations.png)\n",
    "\n",
    "* Affichez les stations vélo'v sur une carte. Utiliser la librairie [GeoPandas](https://geopandas.org/gallery/create_geopandas_from_pandas.html#sphx-glr-gallery-create-geopandas-from-pandas-py). Vous devez obtenir le résultat ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On transforme le dataframe des stations en geodataframe (https://geopandas.org/gallery/create_geopandas_from_pandas.html#sphx-glr-gallery-create-geopandas-from-pandas-py)\n",
    "gdf_stations = geopandas.GeoDataFrame(\n",
    "    df_stations, \n",
    "    geometry=geopandas.points_from_xy(df_stations.longitude, df_stations.latitude))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche les premières lignes du GeoDataFrame pour vérifier l'existance de la colonne géométrie\n",
    "gdf_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche directement les données du geodataframe sur une carte \n",
    "## avec la méthode scatter_mapbox() de la librairie plotly.express:\n",
    "fig = px.scatter_mapbox(gdf_stations,\n",
    "                        lat=gdf_stations.geometry.y,\n",
    "                        lon=gdf_stations.geometry.x,\n",
    "                        hover_name=\"id_velov\",\n",
    "                        zoom=12, mapbox_style=\"carto-positron\")\n",
    "\n",
    "## On supprime les marges autour de la carte\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "\n",
    "## On affiche la carte\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Préparation des données\n",
    "\n",
    "### 3.1. Ajout d'information\n",
    "\n",
    "Avant de pouvoir analyser les données d'historique, on souhaite ajouter quelques informations. Par exemple, le jeu de données initial ne fournit pas directement les trajets (départs / arrivées) des utilisateurs mais seulement le nombre de vélos ou de places disponibles à un instant t (par tranche de 5 minutes). Pour faire une analyse de la fréquentation ou des zones de départs et d'arrivées en fonction du moment de la journée ou de la semaine j'ai calculé les départs et arrivées par tranches de 30min.\n",
    "\n",
    "A partir des tranches de 30 min nous pouvons par exemple inférer le nombre quotidien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On commence par faire une copie de notre DataFrame, pour pouvoir revenir aux données initiales si besoin\n",
    "df_sampled = df_bikes.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Calcul du nombre d'arrivées et de départs quotidiens\n",
    "\n",
    "\n",
    "On peut faire des calculs directement en groupant les lignes grâce à la méthode `groupby()`.\n",
    "\n",
    "Quelles colonnes faut-il regrouper pour pouvoir calculer les départs et arrivées quotidiens ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## La méthode 'transform' permet d'appliquer un calcul au dataframe d'origine (non groupé). \n",
    "## Dans notre cas, on souhaite effectuer une somme sur les colonnes departure30min et arrival30min.\n",
    "\n",
    "## Compléter la liste des colonnes\n",
    "df_sampled[\"daily_departure\"] = df_sampled.groupby([****])['departure30min'].transform('sum')\n",
    "df_sampled[\"daily_arrival\"] = df_sampled.groupby([****])['arrival30min'].transform('sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche 15 lignes aléatoirement pour visualiser le résultat\n",
    "df_sampled.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Distinction semaine / weekend\n",
    "\n",
    "Afin d'analyser les données on souhaite pouvoir distinguer les jours de la semaine des jours de weekend, pour cela nous devons préparer les données afin d'identifier les jours de weekend.\n",
    "\n",
    "1. On défini une fonction qui retourne vrai lorsque la date est un jour de la semaine et faux lorsque c'est le weekend\n",
    "2. On applique cette fonction sur chaque ligne de notre dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## La fonction weekDay, prend 3 paramètres : l'année, le mois et le jour\n",
    "def weekDay(year, month, day):\n",
    "    ## Cette méthode retourne vrai (True) si la date correspond à un jour de la semaine, faux (False) sinon\n",
    "    ## On utilise la fonction datetime() et la méthode weekday()\n",
    "    ## https://docs.python.org/fr/3/library/datetime.html#datetime.datetime\n",
    "    \n",
    "    ****\n",
    "\n",
    "## On vectorise la fonction afin de l'appliquer de manière efficace (en terme de temps de calcul) sur le dataframe\n",
    "isWeekDay = np.vectorize(weekDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On ajoute une nouvelle colonne à partir du résultat de la fonction appliquée sur l'ensemble des lignes du dataframe\n",
    "df_sampled['IsWeekday'] = isWeekDay(****)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on affiche un échantillon du dataframe\n",
    "df_sampled.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Créer une nouvelle colonne `day_of_week` qui contient le jour de la semaine (0 pour lundi, 1 pour mardi, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled['day_of_week'] = df_sampled.apply(lambda row: datetime(row['year'], row['month'], row['day']).weekday(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on affiche un échantillon du dataframe\n",
    "df_sampled.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sauvegarde du jeu de données préparé\n",
    "\n",
    "Afin de pouvoir réutiliser le jeu de données sans refaire tous les traitements on l'enregistre dans un fichier CSV.\n",
    "\n",
    "Utiliser la méthode [to_csv()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) de la librairie Pandas pour enregistrer le dataframe modifié dans un fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On enregistre le dataframe modifié\n",
    "\n",
    "compression_opts = dict(method='zip', archive_name='data-bikes-2.csv')  \n",
    "df_sampled.to_csv('data-bikes-2.zip', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stanza-lexicoscope-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "68d5f9281eab57a7f4901cb150f4c691b1d08935474a18f188e0e3e8f8f412b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
